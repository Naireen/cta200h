{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Monte Carlo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw random samples that follow a predefined probability distribution to:\n",
    "\n",
    "* find (multiple) maxima of the probability distribution\n",
    "* calculate integrals (i.e., expectation values) of functions, weighted by the probability distribution\n",
    "* characterize the probability distribution, find correlations between parameters, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing from a one-dimensional PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing uniformly distributed (pseudo-)random numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computers are deterministic. However, we can generate so-called pseudo-random numbers.\n",
    "\n",
    "Idea: Use some formula whose outcome depends sensitively on the input; iterate.\n",
    "\n",
    "Note: Need starting point for the iteration (random number seed), but that makes the result reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rng(m=2**32, a=1103515245, b=12345):\n",
    "    \"\"\"This function updates the (pseudo-)random number to a new one.\"\"\"\n",
    "    rng.current = (a*rng.current + b) % m\n",
    "    return 1.*rng.current/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rng.current = 101 #setting the random number seed\n",
    "random_numbers = np.array([rng() for i in range(10)]) #Draw a few random numbers\n",
    "plt.hist(random_numbers,range=(0.,1.),bins=10) #plot them\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In numpy, this is already implemented as np.random.random() (or np.random.uniform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(101)\n",
    "random_numbers2 = np.random.random(10)\n",
    "plt.hist(random_numbers,range=(0.,1.),bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing non-uniformly distributed random values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can draw random numbers uniformly between 0 and 1 and then transform them to follow any one-dimensional distribution. In this example, we will use a simple Gaussian distribution.\n",
    "\n",
    "* Calculate cumulative probability distribution (CDF): $\\mathrm{CDF}(x) = \\int_{-\\infty}^x \\mathrm{d}x' P(x)$\n",
    "* invert that function to get the inverse cumulative probability distribution (iCDF)\n",
    "* draw random values $y$ between 0 and 1\n",
    "* evaluate $\\mathrm{iCDF}(y)$ to find values of $x$ following the distribution $P(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xmin = -10. #set up an array of x-values\n",
    "xmax = 10.\n",
    "dx = 0.01\n",
    "x = np.arange(xmin,xmax + dx,dx)\n",
    "\n",
    "sigma = 2. #set the standard deviation of the Gaussian\n",
    "P = 1./(2.*np.pi*sigma**2)**0.5*np.exp(-x**2/(2.*sigma**2)) #Gaussian PDF\n",
    "\n",
    "plt.plot(x,P)\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$P(x)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.special import erf\n",
    "CDF = 0.5*(1. + np.sign(x)*erf(np.abs(x/2**0.5/sigma))) #Gaussian CDF\n",
    "\n",
    "plt.plot(x,CDF)\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'CDF$(x)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.special import erfinv\n",
    "y = np.arange(0.,1.+0.01,0.01)\n",
    "\n",
    "def iCDF(y,sigma): #inverse CDF\n",
    "    return 2**0.5*sigma*erfinv(2.*y - 1.)\n",
    "\n",
    "iCDF_arr = iCDF(y,sigma)\n",
    "plt.plot(y,iCDF_arr)\n",
    "plt.xlabel(r'$y$')\n",
    "plt.ylabel(r'$x$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 200 #Number of random samples to draw\n",
    "\n",
    "yvals = np.random.uniform(0.,1.,n) #Draw uniformly distributed values for y\n",
    "xvals = iCDF(yvals,sigma) #Convert these values to values of x\n",
    "\n",
    "plt.hist(xvals,range=(-10,10),bins=20,normed=True) #plot a histogram for x\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'sample distribution')\n",
    "plt.plot(x,P,label='exact PDF')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these random samples, we can estimate some expectation values, for example the first few moments of the Gaussian distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'zeroth order:', 1., (xvals**0).sum()/n\n",
    "print 'first order:', 0., (xvals**1).sum()/n\n",
    "print 'second order:', sigma**2, (xvals**2).sum()/n\n",
    "print 'third order:', 0., (xvals**3).sum()/n\n",
    "print 'fourth order:', 3.*sigma**4, (xvals**4).sum()/n\n",
    "print 'cos(x):', np.exp(-1./2.*sigma**2), np.cos(xvals).sum()/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In numpy, drawing Gaussian random numbers is also provided as a predefined function (np.random.normal()):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xvals2 = np.random.normal(0.,sigma,n)\n",
    "\n",
    "plt.hist(xvals2,range=(-10,10),bins=20,normed=True) #plot a histogram for x\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'sample distribution')\n",
    "plt.plot(x,P,label='exact PDF')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing from N-dimensional PDFs -- rejection sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In more than one dimension, there is no well-defined cumulative distribution function. Thus, we have to come up with a new idea:\n",
    "\n",
    "* Sample (some region of) N-dimensional space following a simple PDF $Q(x)$ (we will use a uniform distribution.\n",
    "* Add an acceptance-rejection step that accepts the sample $x$ with probability $P(x)/(c\\ Q(x))$.\n",
    "* Choose $c$ such that $P(x) < c\\ Q(x)$ for all $x$ (but ideally not too large).\n",
    "\n",
    "We will use a two-dimensional Gaussian in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Set up a two-dimensional grid for plotting purposes:\n",
    "xvals = np.arange(-10,10.01,0.01)\n",
    "yvals = np.arange(-10,10.01,0.01)\n",
    "gridx, gridy = np.meshgrid(xvals,yvals)\n",
    "\n",
    "#Define the two-dimensional Gaussian:\n",
    "cov_xx = 6.\n",
    "cov_yy = 1.5\n",
    "cov_xy = 1.0\n",
    "cov = np.array([[cov_xx,cov_xy],[cov_xy,cov_yy]])\n",
    "invcov = np.linalg.inv(cov)\n",
    "\n",
    "def twoDGauss(x,y,cov,invcov):\n",
    "    det = np.linalg.det(cov)\n",
    "    norm = 1./(2.*np.pi)/det**0.5\n",
    "    return norm*np.exp(-0.5*(x*(invcov[0,0]*x + invcov[0,1]*y) + y*(invcov[1,0]*x + invcov[1,1]*y)))\n",
    "\n",
    "#Evaluate the Gaussian at all grid points and plot it:\n",
    "G = twoDGauss(gridx,gridy,cov,invcov)\n",
    "\n",
    "plt.imshow(G,cmap=plt.cm.Blues,extent=[xvals.min(),xvals.max(),yvals.max(),yvals.min()])\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$y$')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define drawing step:\n",
    "def draw_sample():\n",
    "    return np.random.uniform(-10,10,2) #two-dimensional uniform distribution\n",
    "\n",
    "#Define the acceptance-rejection step:\n",
    "c = 40.\n",
    "D = 2 #dimension of the parameter space\n",
    "\n",
    "def AcceptReject(c,D,P,*Pargs):\n",
    "    \"\"\"This function returns `True' if the sample is accepted and `False' if not. We use a\n",
    "    variable-length argument list `*Pargs' to be able to use any probability function `P' that we\n",
    "    might come up with\"\"\"\n",
    "    Pval = P(*Pargs)\n",
    "    proposalval = 1./20**D #The proposal density is 1/20*1/20\n",
    "    prob = Pval/(c*proposalval)\n",
    "    return np.random.choice([True,False],p=[prob,1.-prob])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Draw some samples:\n",
    "N = 10000 #number of samples to draw\n",
    "count = 0 #count the accepted samples\n",
    "samples = [] #store the accepted samples\n",
    "\n",
    "for i in range(N):\n",
    "    samp = draw_sample()\n",
    "    acc = AcceptReject(c,D,twoDGauss,samp[0],samp[1],cov,invcov)\n",
    "    if acc:\n",
    "        count += 1\n",
    "        samples.append(samp)\n",
    "samples = np.array(samples)\n",
    "\n",
    "plt.imshow(G,cmap=plt.cm.Blues,extent=[xvals.min(),xvals.max(),yvals.max(),yvals.min()])\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$y$')\n",
    "plt.colorbar()\n",
    "plt.plot(samples[:,0],samples[:,1],'.',color='red')\n",
    "plt.show()\n",
    "print 'acceptance ratio:', 1.*count/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's calculate some moments of the PDF:\n",
    "samples = np.array(samples)\n",
    "print 'mean x:', np.mean(samples[:,0])\n",
    "print 'mean y:', np.mean(samples[:,1])\n",
    "print 'variance in x-direction:', np.mean(samples[:,0]**2)\n",
    "print 'variance in y-direction:', np.mean(samples[:,1]**2)\n",
    "print 'covariance of x and y:', np.mean(samples[:,0]*samples[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what happens if we go to higher dimensions. For simplicity, we use a symmetric Gaussian without correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define the D-dimensional Gaussian:\n",
    "sigma = 2.\n",
    "def DdimGauss(xvec,sigma,D):\n",
    "    det = sigma**(2*D)\n",
    "    norm = 1./(2.*np.pi)**(D/2.)/det**0.5\n",
    "    return norm*np.exp(-0.5*np.dot(xvec,xvec/sigma**2))\n",
    "\n",
    "#Define the drawing step:\n",
    "def draw_sample_Ddim(D):\n",
    "    return np.random.uniform(-10,10,D) #D-dimensional uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Draw some samples:\n",
    "N = 10000 #number of samples to draw\n",
    "count = 0 #count the accepted samples\n",
    "samples = [] #store the accepted samples\n",
    "D = 1\n",
    "\n",
    "#Here we are cheating a bit: Since we know what the maximum of the D-dimensional PDF is, we can\n",
    "#calculate the optimal value of c to use:\n",
    "c = DdimGauss(np.zeros(D),sigma,D)*20.**D\n",
    "print 'c =', c\n",
    "\n",
    "for i in range(N):\n",
    "    samp = draw_sample_Ddim(D)\n",
    "    acc = AcceptReject(c,D,DdimGauss,samp,sigma,D)\n",
    "    if acc:\n",
    "        count += 1\n",
    "        samples.append(samp)\n",
    "\n",
    "print 'acceptance ratio:', 1.*count/N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem is known as \"the curse of dimensionality\"\n",
    "\n",
    "Note: For the special case of Gaussian probability distributions, there is actually a more direct way of drawing random samples (ask me later if you're interested)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Chain Monte Carlo -- Metropolis Hastings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov Chain: Draw random samples in an ordered chain:\n",
    "\n",
    "* \"Markov\" property: Each sample depends on the sample before, but not on any other samples\n",
    "* Pro: Curse of dimensionality less severe\n",
    "* Con: Successive samples are correlated -> need to discard many of them to obtain a set of independent samples\n",
    "\n",
    "Specific example: Metropolis-Hastings\n",
    "\n",
    "* Select a \"proposal density\" $Q(x'|x)$ to draw a new sample $x'$ given a previous sample $x$\n",
    "* If $P(x') \\geq P(x)$, accept the new sample\n",
    "* If $P(x') < P(x)$, accept the new sample with probability $P(x')/P(x)$\n",
    "* If a sample is rejected, the chain stays at the same position (i.e., the old sample is repeated).\n",
    "* Note that the normalization of $P$ doesn't matter.\n",
    "\n",
    "Let's work again with our two-dimensional Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Set up a two-dimensional grid for plotting purposes:\n",
    "xvals = np.arange(-10,10.01,0.01)\n",
    "yvals = np.arange(-10,10.01,0.01)\n",
    "gridx, gridy = np.meshgrid(xvals,yvals)\n",
    "\n",
    "#Define the two-dimensional Gaussian:\n",
    "cov_xx = 6.\n",
    "cov_yy = 1.5\n",
    "cov_xy = 1.0\n",
    "cov = np.array([[cov_xx,cov_xy],[cov_xy,cov_yy]])\n",
    "invcov = np.linalg.inv(cov)\n",
    "def twoDGauss(samp,cov,invcov):\n",
    "    x = samp[0]\n",
    "    y = samp[1]\n",
    "    det = np.linalg.det(cov)\n",
    "    norm = 1./(2.*np.pi)/det**0.5\n",
    "    return norm*np.exp(-0.5*(x*(invcov[0,0]*x + invcov[0,1]*y) + y*(invcov[1,0]*x + invcov[1,1]*y)))\n",
    "\n",
    "#Evaluate the Gaussian at all grid points and plot it:\n",
    "G = twoDGauss([gridx,gridy],cov,invcov)\n",
    "\n",
    "plt.imshow(G,cmap=plt.cm.Blues,extent=[xvals.min(),xvals.max(),yvals.max(),yvals.min()])\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$y$')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define the proposal step (we are using a symmetric Gaussian proposal density):\n",
    "def proposal(oldsamp,sigmaprop,D):\n",
    "    newsamp = oldsamp + np.random.normal(0.,sigmaprop,D)\n",
    "    return newsamp\n",
    "\n",
    "#Define the acceptance-rejection step (return the new sample and a boolean that tells us whether\n",
    "#or not the new sample was accepted):\n",
    "def accept(newsamp,oldsamp,P,*Pargs):\n",
    "    \"\"\"This function returns a boolean variable that tells us whether or not the proposed sample was\n",
    "    accepted and the new sample itself.\"\"\"\n",
    "    newprob = P(newsamp,*Pargs)\n",
    "    oldprob = P(oldsamp,*Pargs)\n",
    "    if newprob >= oldprob:\n",
    "        acc = True\n",
    "        return acc, newsamp\n",
    "    else:\n",
    "        prob = newprob/oldprob\n",
    "        acc = np.random.choice([True,False],p=[prob,1.-prob])\n",
    "        return acc, acc*newsamp + (1. - acc)*oldsamp #Note that this is either newsamp or oldsamp\n",
    "\n",
    "#Define function that runs an entire chain:\n",
    "def run_chain(steps,sigmaprop,D,P,*Pargs):\n",
    "    oldsamp = np.random.uniform(-10,10,D) #Draw a random starting point\n",
    "    count = 0 #Count the number of accepted samples\n",
    "    samples = [oldsamp] #Store all samples\n",
    "    for i in range(steps):\n",
    "        newsamp = proposal(oldsamp,sigmaprop,D) #Propose a new sample\n",
    "        acc, newsamp = accept(newsamp,oldsamp,P,*Pargs) #decide whether or not to accept it\n",
    "        samples.append(newsamp) #Add the sample to the list of samples\n",
    "        if acc:\n",
    "            count += 1\n",
    "        oldsamp = newsamp #Move to the new sample\n",
    "    ar = 1.*count/steps #compute the acceptance ratio\n",
    "    return np.array(samples), ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Run a chain:\n",
    "Nsteps = 200 #number of steps to run the chain for\n",
    "sigmaprop = 1. #width of the proposal distribution\n",
    "D = 2 #dimension of the parameter space\n",
    "samples, ar = run_chain(Nsteps,sigmaprop,D,twoDGauss,cov,invcov) #run the chain\n",
    "print 'acceptance ratio:', ar\n",
    "\n",
    "#Plot the chain on top of the 2D-density:\n",
    "plt.imshow(G,cmap=plt.cm.Blues,extent=[xvals.min(),xvals.max(),yvals.max(),yvals.min()])\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$y$')\n",
    "plt.colorbar()\n",
    "plt.plot(samples[:,0],samples[:,1],'-',color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the x-values of the samples:\n",
    "plt.plot(samples[:,0])\n",
    "plt.xlabel(r'sample number')\n",
    "plt.ylabel(r'$x$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use the plot to determine how many samples to throw out as \"burn-in\":\n",
    "burnin = 50\n",
    "non_burnin_samples = samples[burnin:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#now plot the auto-correlation of the remaining samples:\n",
    "num = np.convolve(non_burnin_samples[:,0],non_burnin_samples[:,0][::-1],mode='same')\n",
    "den = np.convolve(np.ones(len(non_burnin_samples)),np.ones(len(non_burnin_samples)),mode='same')\n",
    "autocorr = num/den\n",
    "plt.plot(np.arange(-non_burnin_samples.shape[0]//2,non_burnin_samples.shape[0]//2,1),autocorr)\n",
    "plt.xlabel(r'difference in sample number')\n",
    "plt.ylabel(r'correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use the plot to determine the correlation length between samples\n",
    "corrlength = 25\n",
    "independentsamples = non_burnin_samples[::corrlength]\n",
    "print independentsamples.shape\n",
    "print 'effective acceptance ratio:', 1.*independentsamples.shape[0]/Nsteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot only the independent samples:\n",
    "plt.imshow(G,cmap=plt.cm.Blues,extent=[xvals.min(),xvals.max(),yvals.max(),yvals.min()])\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$y$')\n",
    "plt.colorbar()\n",
    "plt.plot(independentsamples[:,0],independentsamples[:,1],'.',color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a multimodal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define a multimodal distribution (remember that the normalization doesn't matter):\n",
    "def multimodal(samp,cov,invcov):\n",
    "    x = samp[0]\n",
    "    y = samp[1]\n",
    "    return twoDGauss(samp,cov,invcov) + 0.1*np.exp(-0.5*((x-5.)**2 + (y-5)**2))\n",
    "\n",
    "#Plot it:\n",
    "mm = multimodal([gridx,gridy],cov,invcov)\n",
    "plt.imshow(mm,cmap=plt.cm.Blues,extent=[xvals.min(),xvals.max(),yvals.max(),yvals.min()])\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$y$')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Run a chain:\n",
    "Nsteps = 200\n",
    "sigmaprop = 1.0\n",
    "D = 2\n",
    "samples, ar = run_chain(Nsteps,sigmaprop,D,multimodal,cov,invcov)\n",
    "print 'acceptance ratio:', ar\n",
    "\n",
    "#Plot the chain on top of the 2D-density:\n",
    "plt.imshow(mm,cmap=plt.cm.Blues,extent=[xvals.min(),xvals.max(),yvals.max(),yvals.min()])\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$y$')\n",
    "plt.colorbar()\n",
    "plt.plot(samples[:,0],samples[:,1],'-',color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marginalizing over parameters is trivial; just ignore them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "independent_samples = samples[50::25] #remove burn-in phase and correlated samples\n",
    "\n",
    "x_values = independent_samples[:,0]\n",
    "\n",
    "plt.hist(x_values,range=(-10,10),bins=20,normed=True)\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$P(x)$')\n",
    "plt.show()\n",
    "\n",
    "y_values = independent_samples[:,1]\n",
    "\n",
    "plt.hist(y_values,range=(-10,10),bins=20,normed=True)\n",
    "plt.xlabel(r'$y$')\n",
    "plt.ylabel(r'$P(y)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try again going to higher dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Standard deviation in each direction for the D-dimensional Gaussian:\n",
    "sigma = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Run a chain:\n",
    "D = 1\n",
    "Nsteps = 2000\n",
    "sigmaprop = 1.0\n",
    "samples, ar = run_chain(Nsteps,sigmaprop,D,DdimGauss,sigma,D)\n",
    "print 'acceptance ratio:', ar\n",
    "\n",
    "print 'dimension of the samples:', samples[0].shape\n",
    "\n",
    "#Plot the first dimension of the samples:\n",
    "plt.plot(samples[:,0])\n",
    "plt.xlabel(r'sample number')\n",
    "plt.ylabel(r'$x$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we measure the product of two parameters (in astronomy, this could for example be an observation of a source where both the brightness of the source and the gain factor of the telescope are unknown), so that we have data\n",
    "\n",
    "$d = x\\ y + n$,\n",
    "\n",
    "where $n$ is some observational error. We will assume that we have several measurements and that the errors are Gaussian and independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Simulate a set of Nobs observations:\n",
    "Nobs = 10\n",
    "sigma = 1.0 #the standard deviation of the Gaussian noise\n",
    "x = 2. #fix the true values of the two parameters\n",
    "y = 1.\n",
    "\n",
    "#Draw noise realizations:\n",
    "n = np.random.normal(0.,sigma,Nobs)\n",
    "\n",
    "#Generate a data set:\n",
    "d = x*y + n\n",
    "\n",
    "print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define the likelihood (which is proportional to the posterior, since we are assuming flat priors):\n",
    "def likelihood(samp,d):\n",
    "    x = samp[0]\n",
    "    y = samp[1]\n",
    "    return np.exp(-0.5*((d - x*y)**2/sigma**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Nsteps = 20000\n",
    "sigmaprop = 2.0\n",
    "D = 2\n",
    "samples, ar = run_chain(Nsteps,sigmaprop,D,likelihood,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'acceptance ratio:', ar\n",
    "\n",
    "plt.plot(samples[:,0],samples[:,1],'-',color='red')\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$y$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice: Run several chains with different starting values and make sure that they all converge to the same area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For further reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gibbs sampling: Instead of drawing samples from $P(x,y)$, draw alternately from $P(x|y)$ and $P(y|x)$.\n",
    "* Hamiltonian sampling: Think of the parameters as positions. Add a second set of unknown parameters, corresponding to momenta. Then follow the Hamiltonian equations of motion for some time to propose a new sample.\n",
    "* Various python modules exist that have some of these methods pre-implemented, e.g.:\n",
    "\n",
    "    - emcee (http://dan.iel.fm/emcee/current/)\n",
    "    - pymc (https://pymc-devs.github.io/pymc/)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
